#%%
"""‡∏≠‡∏≤‡∏à‡∏≤‡∏£‡∏¢‡πå‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏ä‡∏∑‡πà‡∏≠cache‡∏Å‡πà‡∏≠‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡πÇ‡∏´‡∏•‡∏îcache‡∏ï‡∏≤‡∏°‡πÇ‡∏Ñ‡πâ‡∏î‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏õ‡∏µ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞"""
import fastf1
from time import sleep

# ‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î cache: ‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏™‡πà‡∏Å‡πà‡∏≠‡∏ô load ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á
fastf1.Cache.enable_cache('cache')  # ‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ

year = 2023
schedule = fastf1.get_event_schedule(year)

# üèÅ ‡∏ß‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏≠‡∏ö Race ('R') ‡∏Ç‡∏≠‡∏á‡∏ó‡∏∏‡∏Å‡∏™‡∏ô‡∏≤‡∏°‡πÉ‡∏ô‡∏õ‡∏µ‡∏ô‡∏±‡πâ‡∏ô
for i, row in schedule.iterrows():
    round_number = row['RoundNumber']
    event_name = row['EventName']
    
    try:
        print(f"\nüì¶ Loading RACE for {event_name} (Round {round_number})...")
        session = fastf1.get_session(year, round_number, 'R')
        session.load()  # üíæ ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡πÄ‡∏ã‡∏ü‡πÄ‡∏Ç‡πâ‡∏≤ cache

        print("‚úÖ Cached successfully.")
        sleep(2)  # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡πÇ‡∏´‡∏•‡∏î‡∏ñ‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏ô‡∏à‡∏ô‡πÇ‡∏î‡∏ô block

    except Exception as e:
        print(f"‚ùå Failed to load {event_name}: {e}")

#%%
import fastf1
from fastf1 import get_event
from fastf1.core import Laps
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
import matplotlib.pyplot as plt
import seaborn as sns

fastf1.Cache.enable_cache('cache')  # ‡πÄ‡∏õ‡∏¥‡∏î cache ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡πÇ‡∏´‡∏•‡∏î

""""STEP 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏õ‡∏µ 2021‚Äì2024 ‡πÄ‡∏â‡∏û‡∏≤‡∏∞ race ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ù‡∏ô‡πÅ‡∏•‡∏∞‡πÅ‡∏Ç‡πà‡∏á‡∏à‡∏ô‡∏à‡∏ö"""
def is_dry_complete_race(event):
    session = event.get_session('R')
    session.load()
    weather = session.weather_data
    if weather['Rainfall'].sum() == 0:
        return True
    return False

def get_dry_race_events(years):
    dry_races = []
    for year in years:
        schedule = fastf1.get_event_schedule(year)
        for _, row in schedule.iterrows():
            try:
                event = get_event(year, row['EventName'])
                if is_dry_complete_race(event):
                    dry_races.append((year, row['EventName']))
            except Exception as e:
                print(f"Skipping {row['EventName']} in {year} due to error: {e}")
    return dry_races

"""STEP 2: ‡∏™‡∏£‡πâ‡∏≤‡∏á Feature ‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£"""
def extract_features_for_event(year, event_name):
    try:
        event = get_event(year, event_name)
        session = event.get_session('R')
        session.load()
        laps = session.laps.pick_quicklaps()

        features = []
        for driver in laps['Driver'].unique():
            driver_laps = laps.pick_driver(driver)

            if len(driver_laps) < 40:
                continue

            # Feature 1: avg start-finish difference
            start_pos = driver_laps['Position'].iloc[0]
            finish_pos = driver_laps['Position'].iloc[-1]
            diff = start_pos - finish_pos

            # Feature 2: braking events (approximation)
            telemetry = driver_laps.get_telemetry()
            braking_events = telemetry['Brake'].sum()

            # Feature 3-5
            avg_speed = telemetry['Speed'].mean()
            avg_rpm = telemetry['RPM'].mean()
            drs_usage_pct = telemetry['DRS'].sum() / len(telemetry) * 100

            features.append({
                'Year': year,
                'Driver': driver,
                'Event': event_name,
                'DiffPos': diff,
                'Brakes': braking_events,
                'Speed': avg_speed,
                'RPM': avg_rpm,
                'DRS_pct': drs_usage_pct
            })
        return pd.DataFrame(features)
    except Exception as e:
        print(f"Error processing {event_name} in {year}: {e}")
        return pd.DataFrame()

"""STEP 3: ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Z-score ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Feature 1"""
def aggregate_features(dry_races):
    df_list = []
    for year, event_name in dry_races:
        df_event = extract_features_for_event(year, event_name)
        df_list.append(df_event)
    df = pd.concat(df_list)
    return df

def compute_zscore_feature1(df):
    result = []
    for year in df['Year'].unique():
        df_year = df[df['Year'] == year]
        yearly_mean = df_year.groupby('Driver')['DiffPos'].mean().reset_index()
        global_mean = df_year['DiffPos'].mean()
        global_std = df_year['DiffPos'].std()
        yearly_mean['Z_DiffPos'] = (yearly_mean['DiffPos'] - global_mean) / global_std
        yearly_mean['Year'] = year
        result.append(yearly_mean[['Year', 'Driver', 'Z_DiffPos']])
    return pd.concat(result)


"""STEP 4: ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° clustering ‡πÅ‡∏•‡∏∞ plot"""
def prepare_for_clustering(df, z_df):
    df_mean = df.groupby(['Year', 'Driver']).agg({
        'Brakes': 'mean',
        'Speed': 'mean',
        'RPM': 'mean',
        'DRS_pct': 'mean'
    }).reset_index()
    df_final = pd.merge(df_mean, z_df, on=['Year', 'Driver'])
    return df_final

def do_clustering(df_final, n_clusters=3):
    features = df_final[['Z_DiffPos', 'Brakes', 'Speed', 'RPM', 'DRS_pct']]
    scaler = StandardScaler()
    scaled = scaler.fit_transform(features)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    df_final['Cluster'] = kmeans.fit_predict(scaled)

    return df_final

"""main"""
years = [2021, 2022, 2023, 2024]
dry_races = get_dry_race_events(years)
df = aggregate_features(dry_races)
z_df = compute_zscore_feature1(df)
df_final = prepare_for_clustering(df, z_df)
df_clustered = do_clustering(df_final, n_clusters=3)

# ‡∏î‡∏π‡∏ú‡∏•
print(df_clustered)

#‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå
data = df_clustered
data.to_csv('output.csv', index=False)  # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô CSV

# %%
"""ver 800 min"""
import fastf1
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.stats import spearmanr
import warnings

# --- Enable cache and suppress warnings ---
fastf1.Cache.enable_cache('cache')
warnings.filterwarnings("ignore", category=UserWarning)

# --- Utility functions ---
def load_clean_session(year, round_number):
    try:
        session = fastf1.get_session(year, round_number, 'R')
        session.load()

        # Skip if it's a rainy session
        if session.weather_data['Rainfall'].sum() > 0:
            return None

        return session
    except Exception:
        return None

def compute_driver_features(session):
    driver_data = {}
    for drv in session.drivers:
        try:
            laps = session.laps.pick_driver(drv)
            result = session.results.loc[drv]

            if result['Status'] != 'Finished' or laps.empty:
                continue

            driver_data[drv] = {
                'Name': session.get_driver(drv)['FullName'],
                'PosDiff': result['GridPosition'] - result['Position'],
                'BrakeCount': 0,
                'TotalLaps': 0,
                'SpeedList': [],
                'RpmList': [],
                'DrsUsage': 0,
                'DrsPossible': 0
            }

            for lap in laps.iterlaps():
                tel = lap[1].get_telemetry()
                driver_data[drv]['BrakeCount'] += ((tel['Brake'] == True) & (tel['Throttle'] == 0)).sum()
                driver_data[drv]['SpeedList'].extend(tel['Speed'].dropna())
                driver_data[drv]['RpmList'].extend(tel['RPM'].dropna())
                driver_data[drv]['DrsUsage'] += tel['DRS'].fillna(0).gt(0).sum()
                driver_data[drv]['DrsPossible'] += tel['DRS'].notna().sum()
                driver_data[drv]['TotalLaps'] += 1

        except Exception:
            continue
    return driver_data

# --- Main processing loop ---
def collect_yearly_data(start_year=2021, end_year=2024): #‡∏•‡∏≠‡∏á‡∏õ‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡πà‡∏≠‡∏ô
    all_drivers = {}
    all_pos_diffs = []

    for year in range(start_year, end_year + 1):
        schedule = fastf1.get_event_schedule(year)
        if schedule.empty or 'RoundNumber' not in schedule.columns:
            continue

        for _, event in schedule.iterrows():
            session = load_clean_session(year, event['RoundNumber'])
            if session is None:
                continue

            features = compute_driver_features(session)

            for drv, stats in features.items():
                key = (year, drv)
                all_pos_diffs.append(stats['PosDiff'])
                if key not in all_drivers:
                    all_drivers[key] = stats
                else:
                    # Aggregate stats
                    all_drivers[key]['PosDiff'] += stats['PosDiff']
                    all_drivers[key]['BrakeCount'] += stats['BrakeCount']
                    all_drivers[key]['TotalLaps'] += stats['TotalLaps']
                    all_drivers[key]['SpeedList'].extend(stats['SpeedList'])
                    all_drivers[key]['RpmList'].extend(stats['RpmList'])
                    all_drivers[key]['DrsUsage'] += stats['DrsUsage']
                    all_drivers[key]['DrsPossible'] += stats['DrsPossible']

    return all_drivers, all_pos_diffs

# --- Build dataframe ---
def build_dataframe(all_drivers, all_pos_diffs):
    pos_diff_mean = np.mean(all_pos_diffs)
    pos_diff_std = np.std(all_pos_diffs, ddof=1)

    records = []
    for (year, drv), v in all_drivers.items():
        drs_pct = (v['DrsUsage'] / v['DrsPossible']) * 100 if v['DrsPossible'] > 0 else 0
        brake_per_corner = v['BrakeCount'] / v['TotalLaps'] if v['TotalLaps'] > 0 else 0
        pos_z = (v['PosDiff'] - pos_diff_mean) / pos_diff_std

        records.append({
            'Year': year,
            'Driver': v['Name'],
            'PosDiffZScore': pos_z,
            'BrakePerCorner': brake_per_corner,
            'AvgSpeed': np.mean(v['SpeedList']) if v['SpeedList'] else 0,
            'AvgRPM': np.mean(v['RpmList']) if v['RpmList'] else 0,
            'DRSUsagePct': drs_pct
        })

    df = pd.DataFrame(records)
    return df.dropna()

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.stats import spearmanr
import matplotlib.pyplot as plt


# --- Clustering + validation ---
def run_clustering(df):
    X = df[['PosDiffZScore', 'BrakePerCorner', 'AvgSpeed', 'AvgRPM', 'DRSUsagePct']]
    X = StandardScaler().fit_transform(X)

    # Elbow method
    inertia = []
    for k in range(1, 8):
        model = KMeans(n_clusters=k, random_state=42)
        model.fit(X)
        inertia.append(model.inertia_)

    plt.plot(range(1, 8), inertia, marker='o')
    plt.title("Elbow Method for K Selection")
    plt.xlabel("Number of Clusters")
    plt.ylabel("Inertia")
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    # Apply KMeans
    kmeans = KMeans(n_clusters=4, random_state=42)
    df['Cluster'] = kmeans.fit_predict(X)

    # Validate using Spearman correlation
    for feature in ['PosDiffZScore', 'BrakePerCorner', 'AvgSpeed', 'AvgRPM', 'DRSUsagePct']:
        print(f"Spearman correlation ({feature} vs. Cluster):",
              spearmanr(df[feature], df['Cluster']).correlation)

    return df


# --- Main ---
if __name__ == '__main__':
    all_drivers, all_pos_diffs = collect_yearly_data()
    df = build_dataframe(all_drivers, all_pos_diffs)
    clustered_df = run_clustering(df)

    # Optionally save to file
    clustered_df.to_csv("clustered_f1_drivers.csv", index=False)
    print("‚úÖ Processing complete.")


#check features

import matplotlib.pyplot as plt
import numpy as np
from matplotlib import gridspec

features = ['PosDiffZScore', 'BrakePerCorner', 'AvgSpeed', 'AvgRPM', 'DRSUsagePct']
n_features = len(features)

# Create figure with a GridSpec layout
fig = plt.figure(figsize=(10, 2 * n_features))
gs = gridspec.GridSpec(n_features, 2, width_ratios=[20, 1])  # 1 narrow column for colorbar

# Keep track of image handles for shared colorbar
ims = []

for i, feature in enumerate(features):
    ax = fig.add_subplot(gs[i, 0])
    pivot_data = clustered_df.groupby('Cluster')[[feature]].mean()
    im = ax.imshow(pivot_data.T, cmap='coolwarm', aspect='auto')
    ims.append(im)

    ax.set_xticks(np.arange(len(pivot_data)))
    ax.set_xticklabels(pivot_data.index, rotation=90)
    ax.set_yticks(np.arange(len(pivot_data.columns)))
    ax.set_yticklabels(pivot_data.columns)

    ax.set_xlabel('Cluster')
    ax.set_ylabel('Feature')
    ax.set_title(f'{feature}', fontsize=12)

# Add one shared colorbar to the right
cax = fig.add_subplot(gs[:, 1])
cbar = fig.colorbar(ims[0], cax=cax)
cbar.set_label('Mean Value')

plt.tight_layout()
plt.show()

